{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the mean-free path using conductance calculations\n",
    "\n",
    "In order to generate the data that is used to fit, run the code in [generate-data.ipynb](generate-data.ipynb). Or download the data, see [README.md](README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import holoviews as hv\n",
    "import pandas as pd\n",
    "hv.notebook_extension()\n",
    "%opts Scatter (color='b') \n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean free path $g \\sim N_{ch} / (1 + L / \\lambda_{MFP})$\n",
    "\n",
    "We fit:\n",
    "$1/g \\sim  (1/N_{ch} + L / (\\lambda_{MFP}N_{ch}))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_hdf('data/mean_free_path.hdf')\n",
    "gb = df.groupby(['disorder', 'L', 'mu', 'num_propagating'])['transmission']\n",
    "conduction = gb.agg({'means' : np.mean, 'vars' : np.var}).reset_index()\n",
    "\n",
    "d = {}\n",
    "for key, gr in conduction.groupby(['L', 'mu']):\n",
    "    d[key] = (hv.Curve((gr.disorder, gr.means), kdims=['disorder'], vdims=['resistance']) *\n",
    "              hv.Spread((gr.disorder, gr.means, gr.vars)) *\n",
    "              hv.Scatter((gr.disorder, gr.means)))[:, 0:25]\n",
    "hv.util.Dynamic(hv.HoloMap(d, kdims=['L', 'mu']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a simple polyfit to find  $\\lambda_{MFP}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for (mu, disorder), gr in conduction.groupby(['mu', 'disorder']):\n",
    "    modes = gr.num_propagating.values[0]\n",
    "    fit = np.polyfit(gr.L, 1/gr.means, deg=1)\n",
    "    mfp = 1 / (modes * fit[0])\n",
    "    print(\"mu: {} meV, disorder: {} meV, mfp: {:.0f} nm, num modes: {}\".format(mu, disorder, mfp, modes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using bootstrapping to find $\\lambda_{MFP}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from scipy import optimize\n",
    "\n",
    "def fit_bootstrap(p0, datax, datay, function, yerr_systematic=0.0):\n",
    "    \"\"\"From http://stackoverflow.com/a/21844726/3447047\"\"\"\n",
    "    errfunc = lambda p, x, y: function(x, p) - y\n",
    "\n",
    "    # Fit first time\n",
    "    pfit, perr = optimize.leastsq(errfunc, p0, args=(datax, datay), full_output=0)\n",
    "\n",
    "\n",
    "    # Get the stdev of the residuals\n",
    "    residuals = errfunc(pfit, datax, datay)\n",
    "    sigma_res = np.std(residuals)\n",
    "\n",
    "    sigma_err_total = np.sqrt(sigma_res**2 + yerr_systematic**2)\n",
    "\n",
    "    # 100 random data sets are generated and fitted\n",
    "    ps = []\n",
    "    for i in range(100):\n",
    "\n",
    "        randomDelta = np.random.normal(0., sigma_err_total, len(datay))\n",
    "        randomdataY = datay + randomDelta\n",
    "\n",
    "        randomfit, randomcov = optimize.leastsq(\n",
    "            errfunc, p0, args=(datax, randomdataY), full_output=0)\n",
    "\n",
    "        ps.append(randomfit) \n",
    "\n",
    "    ps = np.array(ps)\n",
    "    mean_pfit = np.mean(ps,0)\n",
    "\n",
    "    # You can choose the confidence interval that you want for your\n",
    "    # parameter estimates: \n",
    "    Nsigma = 2. # 1sigma gets approximately the same as methods above\n",
    "                # 1sigma corresponds to 68.3% confidence interval\n",
    "                # 2sigma corresponds to 95.44% confidence interval\n",
    "    err_pfit = Nsigma * np.std(ps, 0) \n",
    "\n",
    "    pfit_bootstrap = mean_pfit\n",
    "    perr_bootstrap = err_pfit\n",
    "    return pfit_bootstrap, perr_bootstrap \n",
    "\n",
    "def inv_conductance(L, lambda_mfp, N_ch):\n",
    "    return 1 / N_ch + L / (lambda_mfp * N_ch)\n",
    "\n",
    "for (mu, disorder), gr in conduction.groupby(['mu', 'disorder']):\n",
    "    modes = gr.num_propagating.values[0]\n",
    "    ff = partial(inv_conductance, N_ch=modes)\n",
    "    xdata = gr.L\n",
    "    ydata = 1 / gr.means\n",
    "    pstart = 1000\n",
    "    pfit, perr = fit_bootstrap(pstart, xdata, ydata, ff)\n",
    "    print(\"mu: {} meV, disorder: {} meV, mfp: {:.0f} nm Â± {:.0f}\".format(mu, disorder, pfit[0], perr[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
